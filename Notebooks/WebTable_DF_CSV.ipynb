{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WebTable_DF_CSV.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxqdCcv4BPym"
      },
      "source": [
        "\"\"\"\n",
        "Dear Candidate,\n",
        "\n",
        "ALERT: Your Assignment#2 submission Deadline is on 14-August 11:59 P.M. IST. \n",
        "\n",
        "Assignment#2:\n",
        " \n",
        "Problem Statement:\n",
        "Step1: Study the Complete File Operations Lectures and Data Analysis Tecniques and Manipulation Lectures (Section #4 and #5 of the \n",
        "Udemy Intern Kit).\n",
        " \n",
        "1. Create a single .xlsx file with 10 sheets inside filled with dummy data.\n",
        "2. Read the .xlsx file using pandas\n",
        "3. Export every single sheet of the .xlsx file as a .csv file. (The Output should produce 10 .csv files that contains values of each \n",
        "sheet of .xlsx file respectively)\n",
        " \n",
        " \n",
        "Step2: Email the following files to amanda@takenmind.com within the deadline date:\n",
        "A. Code File (.py file)\n",
        "B. Input File (.xlsx file)\n",
        " \n",
        "The subject of your Email: <Your Name> - Assignment#2\n",
        "\"\"\"\n",
        "\n",
        "#Create a single .xlsx file with 10 sheets inside filled with dummy data.\n",
        "\n",
        "\n",
        "\n",
        "#for writing to excel(xlsx) we will be needing this!\n",
        "try:\n",
        "  import XlsxWriter\n",
        "except ModuleNotFoundError:\n",
        "  print(\"XlsxWriter is not installed!!\")\n",
        "  !pip install XlsxWriter\n",
        "      \n",
        "#scrape a table from a webpage\n",
        "import requests\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "urls=[\"\"]\n",
        "\n",
        "def get_dataframes(url):\n",
        "  html = requests.get(url).content\n",
        "  df_list = pd.read_html(html)\n",
        "  print(len(df_list),\" Dataframes Returned\")\n",
        "  return df_list\n",
        "\n",
        "url = \"http://www.inwea.org/wind-energy-in-india/wind-power-potential/\"\n",
        "dfs_list=get_dataframes(url)\n",
        "\n",
        "\n",
        "excel_path=os.getcwd()\n",
        "writer = pd.ExcelWriter(excel_path, engine='xlsxwriter')\n",
        "i=0\n",
        "for each_df in dfs_list:\n",
        "  print(\"Parsing Excel Sheet \",i,\" : \",url)\n",
        "  i+=1\n",
        "  each_df.to_excel(writer, sheet_name=table_name, index=False)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAeftr_6GzH0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "866d0b3e-c925-4dd1-b9f0-2bb26236378b"
      },
      "source": [
        "url = \"http://www.inwea.org/wind-energy-in-india/wind-power-potential/\"\n",
        "from urllib.parse import urlparse\n",
        "def extract_domain(url, remove_http=True):\n",
        "    uri = urlparse(url)\n",
        "    if remove_http:\n",
        "        domain_name = f\"{uri.netloc}\"\n",
        "    else:\n",
        "        domain_name = f\"{uri.netloc}://{uri.netloc}\"\n",
        "    return domain_name\n",
        "#url = 'https://pydeep.com/get-domain-name-from-url-python'\n",
        "print(\"Original: \", url)\n",
        "print(\"Extracted: \", extract_domain(url))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  http://www.inwea.org/wind-energy-in-india/wind-power-potential/\n",
            "Extracted:  www.inwea.org\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5SC2T21G5tj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9923545c-e16d-4641-8927-26ca2aaa1e5b"
      },
      "source": [
        "extract_domain(url).split('.')[1].upper()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'INWEA'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EA6c_QPLIc0j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "769d83d6-de18-41f1-aee9-621edaf8b266"
      },
      "source": [
        "import urllib.parse\n",
        "o = urllib.parse.urlsplit('https://user:pass@www.example.com:8080/dir/page.html?q1=test&q2=a2#anchor1')\n",
        "\"\"\">>> o.scheme\n",
        "'https'\n",
        ">>> o.netloc\n",
        "'user:pass@www.example.com:8080'\n",
        ">>> o.hostname\n",
        "'www.example.com'\n",
        ">>> o.port\n",
        "8080\n",
        ">>> o.path\n",
        "'/dir/page.html'\n",
        ">>> o.query\n",
        "'q1=test&q2=a2'\n",
        ">>> o.fragment\n",
        "'anchor1'\n",
        ">>> o.username\n",
        "'user'\n",
        ">>> o.password\n",
        "'pass'\"\"\"\n",
        "\n",
        "o.path.split('/')[-1].strip('.html')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'page'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFyEuezFJcUZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z9ZsoH6JcbM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQhzrZKuJcZ2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAb4hfy4JcYE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNlmlGybI8yl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "5de45713-a1d5-446a-e004-4a5b6d323f9f"
      },
      "source": [
        "try:\n",
        "  import XlsxWriter\n",
        "except ModuleNotFoundError:\n",
        "  print(\"XlsxWriter is not installed!!\")\n",
        "  get_ipython().system(\"pip install XlsxWriter\")\n",
        "      \n",
        "#scrape a table from a webpage\n",
        "import requests\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "from urllib.parse import urlparse,urlsplit\n",
        "\n",
        "\n",
        "\n",
        "urls=[\"https://www.macrotrends.net/countries/IND/india/gdp-growth-rate\",\n",
        "      \"http://www.inwea.org/wind-energy-in-india/wind-power-potential\",\n",
        "      \"https://en.wikipedia.org/wiki/List_of_districts_in_India\",\n",
        "      \"https://en.wikipedia.org/wiki/List_of_Indian_people_by_net_worth\",\n",
        "      \"https://en.wikipedia.org/wiki/States_and_union_territories_of_India\",\n",
        "      \"https://en.wikipedia.org/wiki/List_of_governors-general_of_India\",\n",
        "      \"https://en.wikipedia.org/wiki/List_of_Indian_independence_activists\",\n",
        "      \"https://en.wikipedia.org/wiki/List_of_Indian_Grammy_Award_winners_and_nominees\",\n",
        "      \"https://en.wikipedia.org/wiki/List_of_Indian_Academy_Award_winners_and_nominees\",\n",
        "      \"https://en.wikipedia.org/wiki/List_of_highest-grossing_Indian_films\"\n",
        "      ]\n",
        "\n",
        "#get max from each site =1\n",
        "#if df too small then don't add\n",
        "\n",
        "\n",
        "#convert the sheetname- remove _ and - , put title case and remove spaces\n",
        "def modify_name(my_str):\n",
        "  replaced=my_str.replace(\"_\", \" \").replace(\"-\", \" \")\n",
        "  return replaced.title().replace(\" \",\"\")\n",
        "print(len(urls))\n",
        "for url in urls:\n",
        "  parsed=urlsplit(url)\n",
        "  sheet_name=parsed.path.split('/')[-1]\n",
        "  print(modify_name(sheet_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XlsxWriter is not installed!!\n",
            "Requirement already satisfied: XlsxWriter in /usr/local/lib/python3.6/dist-packages (1.3.3)\n",
            "10\n",
            "GdpGrowthRate\n",
            "WindPowerPotential\n",
            "ListOfDistrictsInIndia\n",
            "ListOfIndianPeopleByNetWorth\n",
            "StatesAndUnionTerritoriesOfIndia\n",
            "ListOfGovernorsGeneralOfIndia\n",
            "ListOfIndianIndependenceActivists\n",
            "ListOfIndianGrammyAwardWinnersAndNominees\n",
            "ListOfIndianAcademyAwardWinnersAndNominees\n",
            "ListOfHighestGrossingIndianFilms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYtY9-JxPa70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "608aea78-8dc7-48be-ee01-2fe2e67f3d9d"
      },
      "source": [
        "def get_dataframes(url):\n",
        "  html = requests.get(url).content\n",
        "  df_list = pd.read_html(html)\n",
        "  #print(len(df_list),\" Dataframes Returned\")\n",
        "  return df_list\n",
        "\n",
        "\n",
        "def filter_dfs(dfs_list,min_rows=5):\n",
        "  new_dfs_list=[]\n",
        "  for each_df in dfs_list:\n",
        "    if(len(each_df)>min_rows):\n",
        "      new_dfs_list.append(each_df)\n",
        "  return new_dfs_list\n",
        "\n",
        "#to avoid InvalidWorksheetName: Excel worksheet name 'StatesAndUnionTerritoriesOfIndia1' must be <= 31 chars.\n",
        "def crop_name(name,thres=20):\n",
        "  if len(name)<thres:\n",
        "    return name\n",
        "  else:\n",
        "    return name[:thres]\n",
        "\n",
        "\n",
        "excel_path=os.path.join(os.getcwd(),\"output.xlsx\")\n",
        "writer = pd.ExcelWriter(excel_path, engine='xlsxwriter')\n",
        "i=0\n",
        "for url in urls:\n",
        "  parsed=urlsplit(url)\n",
        "  sheet_name=parsed.path.split('/')[-1]\n",
        "  mod_sheet_name=crop_name(modify_name(sheet_name))\n",
        "  print(mod_sheet_name)\n",
        "\n",
        "  dfs_list=get_dataframes(url)\n",
        "  filtered_dfs_list=filter_dfs(dfs_list)\n",
        "  filtered_dfs_list=[filtered_dfs_list[0]]\n",
        "  for each_df in filtered_dfs_list:\n",
        "    print(\"Parsing Excel Sheet \",i,\" : \",mod_sheet_name+str(i))\n",
        "    i+=1\n",
        "    each_df.to_excel(writer, sheet_name=mod_sheet_name+str(i), index=True)\n",
        "writer.save()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GdpGrowthRate\n",
            "4  Dataframes Returned\n",
            "Parsing Excel Sheet  0  :  GdpGrowthRate0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-ac35dfa33faf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Parsing Excel Sheet \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" : \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmod_sheet_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0meach_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmod_sheet_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_excel\u001b[0;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes)\u001b[0m\n\u001b[1;32m   2179\u001b[0m             \u001b[0mstartcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstartcol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2180\u001b[0m             \u001b[0mfreeze_panes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreeze_panes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2181\u001b[0;31m             \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2182\u001b[0m         )\n\u001b[1;32m   2183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/formats/excel.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0mstartrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstartrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0mstartcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstartcol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m             \u001b[0mfreeze_panes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreeze_panes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m         )\n\u001b[1;32m    737\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mneed_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlsxwriter.py\u001b[0m in \u001b[0;36mwrite_cells\u001b[0;34m(self, cells, sheet_name, startrow, startcol, freeze_panes)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mwks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze_panes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreeze_panes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcells\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m             \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_with_fmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/formats/excel.py\u001b[0m in \u001b[0;36mget_formatted_cells\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_formatted_cells\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m             \u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/formats/excel.py\u001b[0m in \u001b[0;36m_format_header_mi\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m                 raise NotImplementedError(\n\u001b[0;32m--> 448\u001b[0;31m                     \u001b[0;34m\"Writing to Excel with MultiIndex columns and no \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m                     \u001b[0;34m\"index ('index'=False) is not yet implemented.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 )\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Writing to Excel with MultiIndex columns and no index ('index'=False) is not yet implemented."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHdoacA4JTVw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yoir_KoiJTiU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lieaC58kJTf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "9d908e46-a057-436d-c907-7ca30eba9a05"
      },
      "source": [
        "#for writing to excel(xlsx) we will be needing XlsxWriter, please install it first if you don't have it!\n",
        "try:\n",
        "  import XlsxWriter\n",
        "except ModuleNotFoundError:\n",
        "  print(\"XlsxWriter is not installed!!\")\n",
        "  get_ipython().system(\"pip install XlsxWriter\")\n",
        "      \n",
        "#to scrape a table from a webpage\n",
        "from urllib.parse import urlparse,urlsplit\n",
        "import requests\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "urls=[\"https://www.macrotrends.net/countries/IND/india/gdp-growth-rate\",\n",
        "      \"http://www.inwea.org/wind-energy-in-india/wind-power-potential\",\n",
        "      \"https://en.wikipedia.org/wiki/List_of_districts_in_India\",\n",
        "      \"https://en.wikipedia.org/wiki/List_of_Indian_people_by_net_worth\",\n",
        "      \"https://en.wikipedia.org/wiki/States_and_union_territories_of_India\",\n",
        "      \"https://en.wikipedia.org/wiki/List_of_governors-general_of_India\",\n",
        "      \"https://en.wikipedia.org/wiki/List_of_Indian_independence_activists\",\n",
        "      \"https://en.wikipedia.org/wiki/List_of_Indian_Grammy_Award_winners_and_nominees\",\n",
        "      \"https://en.wikipedia.org/wiki/List_of_Indian_Academy_Award_winners_and_nominees\",\n",
        "      \"https://en.wikipedia.org/wiki/List_of_highest-grossing_Indian_films\"\n",
        "      ]\n",
        "\n",
        "\n",
        "print(len(urls),\"Urls Found\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XlsxWriter is not installed!!\n",
            "Requirement already satisfied: XlsxWriter in /usr/local/lib/python3.6/dist-packages (1.3.3)\n",
            "10 Urls Found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ2n0SXiJTd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "4f195231-b0d3-4159-862e-d5078220dad2"
      },
      "source": [
        "#convert the sheetname- remove _ and - , put title case and remove spaces\n",
        "def modify_name(my_str):\n",
        "  replaced=my_str.replace(\"_\", \" \").replace(\"-\", \" \")\n",
        "  return replaced.title().replace(\" \",\"\")\n",
        "\n",
        "\n",
        "#get all tables from a url\n",
        "def get_dataframes(url):\n",
        "  html = requests.get(url).content\n",
        "  df_list = pd.read_html(html)\n",
        "  #print(len(df_list),\" Dataframes Returned\")\n",
        "  return df_list\n",
        "\n",
        "#if df is too small then don't add it\n",
        "def filter_dfs(dfs_list,min_rows=10):\n",
        "  new_dfs_list=[]\n",
        "  for each_df in dfs_list:\n",
        "    if(len(each_df)>min_rows):\n",
        "      new_dfs_list.append(each_df)\n",
        "  return new_dfs_list\n",
        "\n",
        "#to avoid InvalidWorksheetName: Excel worksheet name 'StatesAndUnionTerritoriesOfIndia1' must be <= 31 chars.\n",
        "def crop_name(name,thres=29):\n",
        "  if len(name)<thres:\n",
        "    return name\n",
        "  else:\n",
        "    return name[:thres]\n",
        "\n",
        "#to get first n elements from list only\n",
        "def crop_list(lst,thres=29):\n",
        "  if len(lst)<thres:\n",
        "    return lst\n",
        "  else:\n",
        "    return lst[:thres]\n",
        "\n",
        "\n",
        "def urls_to_excel(urls,excel_path=None,get_max=10,min_rows=10,crop_name_thres=29):\n",
        "  excel_path=os.path.join(os.getcwd(),\"Excel_Multiple_Sheets_Output.xlsx\") if excel_path==None else excel_path\n",
        "  writer = pd.ExcelWriter(excel_path, engine='xlsxwriter')\n",
        "  i=0\n",
        "  for url in urls:\n",
        "    parsed=urlsplit(url)\n",
        "    sheet_name=parsed.path.split('/')[-1]\n",
        "    mod_sheet_name=crop_name(modify_name(sheet_name),thres=crop_name_thres)\n",
        "    \n",
        "    dfs_list=get_dataframes(url)\n",
        "    filtered_dfs_list=filter_dfs(dfs_list,min_rows=min_rows)\n",
        "    filtered_dfs_list=crop_list(filtered_dfs_list,thres=get_max)\n",
        "    for each_df in filtered_dfs_list:\n",
        "      print(\"Parsing Excel Sheet \",\" : \",str(i)+mod_sheet_name)\n",
        "      i+=1\n",
        "      each_df.to_excel(writer, sheet_name=str(i)+mod_sheet_name, index=True)\n",
        "  writer.save()\n",
        "urls_to_excel(urls)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing Excel Sheet   :  0GdpGrowthRate\n",
            "Parsing Excel Sheet   :  1GdpGrowthRate\n",
            "Parsing Excel Sheet   :  2WindPowerPotential\n",
            "Parsing Excel Sheet   :  3WindPowerPotential\n",
            "Parsing Excel Sheet   :  4ListOfDistrictsInIndia\n",
            "Parsing Excel Sheet   :  5ListOfDistrictsInIndia\n",
            "Parsing Excel Sheet   :  6ListOfDistrictsInIndia\n",
            "Parsing Excel Sheet   :  7ListOfDistrictsInIndia\n",
            "Parsing Excel Sheet   :  8ListOfDistrictsInIndia\n",
            "Parsing Excel Sheet   :  9ListOfDistrictsInIndia\n",
            "Parsing Excel Sheet   :  10ListOfDistrictsInIndia\n",
            "Parsing Excel Sheet   :  11ListOfDistrictsInIndia\n",
            "Parsing Excel Sheet   :  12ListOfDistrictsInIndia\n",
            "Parsing Excel Sheet   :  13ListOfDistrictsInIndia\n",
            "Parsing Excel Sheet   :  14ListOfIndianPeopleByNetWorth\n",
            "Parsing Excel Sheet   :  15StatesAndUnionTerritoriesOfIn\n",
            "Parsing Excel Sheet   :  16StatesAndUnionTerritoriesOfIn\n",
            "Parsing Excel Sheet   :  17ListOfGovernorsGeneralOfIndia\n",
            "Parsing Excel Sheet   :  18ListOfIndianIndependenceActiv\n",
            "Parsing Excel Sheet   :  19ListOfIndianGrammyAwardWinner\n",
            "Parsing Excel Sheet   :  20ListOfIndianAcademyAwardWinne\n",
            "Parsing Excel Sheet   :  21ListOfHighestGrossingIndianFi\n",
            "Parsing Excel Sheet   :  22ListOfHighestGrossingIndianFi\n",
            "Parsing Excel Sheet   :  23ListOfHighestGrossingIndianFi\n",
            "Parsing Excel Sheet   :  24ListOfHighestGrossingIndianFi\n",
            "Parsing Excel Sheet   :  25ListOfHighestGrossingIndianFi\n",
            "Parsing Excel Sheet   :  26ListOfHighestGrossingIndianFi\n",
            "Parsing Excel Sheet   :  27ListOfHighestGrossingIndianFi\n",
            "Parsing Excel Sheet   :  28ListOfHighestGrossingIndianFi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrRkxCmuJTb-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTmJUqRAZe6u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mfJpPehZfCJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "d01e7c1f-95d3-471e-8d3e-c7f79c99225f"
      },
      "source": [
        "#for writing to excel(xlsx) we will be needing XlsxWriter, please install it first if you don't have it!\n",
        "try:\n",
        "  import XlsxWriter\n",
        "except ModuleNotFoundError:\n",
        "  print(\"XlsxWriter is not installed!!\")\n",
        "  get_ipython().system(\"pip install XlsxWriter\")\n",
        "      \n",
        "#to scrape a table from a webpage\n",
        "from urllib.parse import urlparse,urlsplit\n",
        "import requests\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "urls=[\"https://www.macrotrends.net/countries/IND/india/gdp-growth-rate\",\n",
        "      \"http://www.inwea.org/wind-energy-in-india/wind-power-potential\",\n",
        "      \"https://en.wikipedia.org/wiki/List_of_districts_in_India\",\n",
        "      \"https://en.wikipedia.org/wiki/List_of_Indian_people_by_net_worth\",\n",
        "      \"https://en.wikipedia.org/wiki/States_and_union_territories_of_India\",\n",
        "      \"https://en.wikipedia.org/wiki/List_of_governors-general_of_India\",\n",
        "      \"https://en.wikipedia.org/wiki/List_of_Indian_independence_activists\",\n",
        "      \"https://en.wikipedia.org/wiki/List_of_Indian_Grammy_Award_winners_and_nominees\",\n",
        "      \"https://en.wikipedia.org/wiki/List_of_Indian_Academy_Award_winners_and_nominees\",\n",
        "      \"https://en.wikipedia.org/wiki/List_of_highest-grossing_Indian_films\"\n",
        "      ]\n",
        "\n",
        "\n",
        "print(len(urls),\"Urls Found\")\n",
        "\n",
        "#convert the sheetname- remove _ and - , put title case and remove spaces\n",
        "def modify_name(my_str):\n",
        "  replaced=my_str.replace(\"_\", \" \").replace(\"-\", \" \")\n",
        "  return replaced.title().replace(\" \",\"\")\n",
        "\n",
        "\n",
        "#get all tables from a url\n",
        "def get_dataframes(url):\n",
        "  html = requests.get(url).content\n",
        "  df_list = pd.read_html(html)\n",
        "  #print(len(df_list),\" Dataframes Returned\")\n",
        "  return df_list\n",
        "\n",
        "#if df is too small then don't add it\n",
        "def filter_dfs(dfs_list,min_rows=10):\n",
        "  new_dfs_list=[]\n",
        "  for each_df in dfs_list:\n",
        "    if(len(each_df)>min_rows):\n",
        "      new_dfs_list.append(each_df)\n",
        "  return new_dfs_list\n",
        "\n",
        "#to avoid InvalidWorksheetName: Excel worksheet name 'StatesAndUnionTerritoriesOfIndia1' must be <= 31 chars.\n",
        "def crop_name(name,thres=29):\n",
        "  if len(name)<thres:\n",
        "    return name\n",
        "  else:\n",
        "    return name[:thres]\n",
        "\n",
        "#to get first n elements from list only\n",
        "def crop_list(lst,thres=29):\n",
        "  if len(lst)<thres:\n",
        "    return lst\n",
        "  else:\n",
        "    return lst[:thres]\n",
        "\n",
        "#converts urls to dataframes to excel sheets\n",
        "#get_max= get the maximum number of tables from each url\n",
        "#min_rows= the minimum number of rows in each table to save it to the excel sheet\n",
        "#crop_name_thres= some excel sheets can get quite huge sheet names which blows up the code\n",
        "#so crop the sheet name for the better purpose\n",
        "\n",
        "def urls_to_excel(urls,excel_path=None,get_max=10,min_rows=0,crop_name_thres=29):\n",
        "  excel_path=os.path.join(os.getcwd(),\"Excel_Multiple_Sheets_Output.xlsx\") if excel_path==None else excel_path\n",
        "  writer = pd.ExcelWriter(excel_path, engine='xlsxwriter')\n",
        "  i=0\n",
        "  for url in urls:\n",
        "    parsed=urlsplit(url)\n",
        "    sheet_name=parsed.path.split('/')[-1]\n",
        "    mod_sheet_name=crop_name(modify_name(sheet_name),thres=crop_name_thres)\n",
        "    \n",
        "    dfs_list=get_dataframes(url)\n",
        "    filtered_dfs_list=filter_dfs(dfs_list,min_rows=min_rows)\n",
        "    filtered_dfs_list=crop_list(filtered_dfs_list,thres=get_max)\n",
        "    for each_df in filtered_dfs_list:\n",
        "      print(\"Parsing Excel Sheet \",\" : \",str(i).zfill(2)+mod_sheet_name)\n",
        "      i+=1\n",
        "      each_df.to_excel(writer, sheet_name=str(i).zfill(2)+mod_sheet_name, index=True)\n",
        "  writer.save()\n",
        "urls_to_excel(urls,get_max=1,min_rows=10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XlsxWriter is not installed!!\n",
            "Collecting XlsxWriter\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/98/17875723b6814fc4d0fc03f0997ee00de2dbd78cf195e2ec3f2c9c789d40/XlsxWriter-1.3.3-py2.py3-none-any.whl (144kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 8.0MB/s \n",
            "\u001b[?25hInstalling collected packages: XlsxWriter\n",
            "Successfully installed XlsxWriter-1.3.3\n",
            "10 Urls Found\n",
            "Parsing Excel Sheet   :  00GdpGrowthRate\n",
            "Parsing Excel Sheet   :  01WindPowerPotential\n",
            "Parsing Excel Sheet   :  02ListOfDistrictsInIndia\n",
            "Parsing Excel Sheet   :  03ListOfIndianPeopleByNetWorth\n",
            "Parsing Excel Sheet   :  04StatesAndUnionTerritoriesOfIn\n",
            "Parsing Excel Sheet   :  05ListOfGovernorsGeneralOfIndia\n",
            "Parsing Excel Sheet   :  06ListOfIndianIndependenceActiv\n",
            "Parsing Excel Sheet   :  07ListOfIndianGrammyAwardWinner\n",
            "Parsing Excel Sheet   :  08ListOfIndianAcademyAwardWinne\n",
            "Parsing Excel Sheet   :  09ListOfHighestGrossingIndianFi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_Q-5VkTZe_j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "c655caac-9a1d-4be7-be8f-cbacb0331eae"
      },
      "source": [
        "from xlrd import open_workbook\n",
        "import csv\n",
        "\n",
        "\n",
        "\n",
        "def excel_to_csv(excel_path,csv_dir):\n",
        "  wb = open_workbook(excel_path)\n",
        "  root_dir=csv_dir\n",
        "  for i in range(wb.nsheets):\n",
        "      sheet = wb.sheet_by_index(i)\n",
        "      out_file_name=root_dir+\"%s.csv\" %(sheet.name.replace(\" \",\"\"))\n",
        "      print (\"Parsing\",sheet.name, \" to : \",out_file_name)\n",
        "      with open(out_file_name, \"w\") as file:\n",
        "          writer = csv.writer(file, delimiter = \",\")\n",
        "          #print (sheet, sheet.name, sheet.ncols, sheet.nrows)\n",
        "          header = [cell.value for cell in sheet.row(0)]\n",
        "          writer.writerow(header)\n",
        "          for row_idx in range(1, sheet.nrows):\n",
        "              row = [int(cell.value) if isinstance(cell.value, float) else cell.value\n",
        "                    for cell in sheet.row(row_idx)]\n",
        "              writer.writerow(row)\n",
        "\n",
        "excel_to_csv(excel_path='/content/Excel_Multiple_Sheets_Output.xlsx',csv_dir='/content/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing 01GdpGrowthRate  to :  /content/01GdpGrowthRate.csv\n",
            "Parsing 02WindPowerPotential  to :  /content/02WindPowerPotential.csv\n",
            "Parsing 03ListOfDistrictsInIndia  to :  /content/03ListOfDistrictsInIndia.csv\n",
            "Parsing 04ListOfIndianPeopleByNetWorth  to :  /content/04ListOfIndianPeopleByNetWorth.csv\n",
            "Parsing 05StatesAndUnionTerritoriesOfIn  to :  /content/05StatesAndUnionTerritoriesOfIn.csv\n",
            "Parsing 06ListOfGovernorsGeneralOfIndia  to :  /content/06ListOfGovernorsGeneralOfIndia.csv\n",
            "Parsing 07ListOfIndianIndependenceActiv  to :  /content/07ListOfIndianIndependenceActiv.csv\n",
            "Parsing 08ListOfIndianGrammyAwardWinner  to :  /content/08ListOfIndianGrammyAwardWinner.csv\n",
            "Parsing 09ListOfIndianAcademyAwardWinne  to :  /content/09ListOfIndianAcademyAwardWinne.csv\n",
            "Parsing 10ListOfHighestGrossingIndianFi  to :  /content/10ListOfHighestGrossingIndianFi.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOgSFUtFZe4-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO1wFSSeZe1o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDoQPxVwJTYt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc-CW0B09vK8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVGO7neR9vON"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NL1ZVEX9vRu",
        "outputId": "d1aaee98-5080-4b07-949e-76732b77fc7d"
      },
      "source": [
        "#for writing to excel(xlsx) we will be needing XlsxWriter, please install it first if you don't have it!\n",
        "try:\n",
        "  import XlsxWriter\n",
        "except ModuleNotFoundError:\n",
        "  print(\"XlsxWriter is not installed!!\")\n",
        "  get_ipython().system(\"pip install XlsxWriter\")\n",
        "\n",
        "#to scrape a table from a webpage\n",
        "from urllib.parse import urlparse,urlsplit\n",
        "import requests\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "urls=[\"https://www.openacessjournal.com/impact-factor-list-journals\",\n",
        "      \"https://www.openacessjournal.com/indexed-journals-list\",\n",
        "      \"https://www.openacessjournal.com/blog/scopus-indexed-journals/\"\n",
        "      ]\n",
        "\n",
        "\n",
        "print(len(urls),\"Urls Found\")\n",
        "\n",
        "#convert the sheetname- remove _ and - , put title case and remove spaces\n",
        "def modify_name(my_str):\n",
        "  replaced=my_str.replace(\"_\", \" \").replace(\"-\", \" \")\n",
        "  return replaced.title().replace(\" \",\"\")\n",
        "\n",
        "\n",
        "#get all tables from a url\n",
        "def get_dataframes(url):\n",
        "  html = requests.get(url).content\n",
        "  df_list = pd.read_html(html)\n",
        "  #print(len(df_list),\" Dataframes Returned\")\n",
        "  return df_list\n",
        "\n",
        "#if df is too small then don't add it\n",
        "def filter_dfs(dfs_list,min_rows=10):\n",
        "  new_dfs_list=[]\n",
        "  for each_df in dfs_list:\n",
        "    if(len(each_df)>min_rows):\n",
        "      new_dfs_list.append(each_df)\n",
        "  return new_dfs_list\n",
        "\n",
        "#to avoid InvalidWorksheetName: Excel worksheet name 'StatesAndUnionTerritoriesOfIndia1' must be <= 31 chars.\n",
        "def crop_name(name,thres=29):\n",
        "  if len(name)<thres:\n",
        "    return name\n",
        "  else:\n",
        "    return name[:thres]\n",
        "\n",
        "#to get first n elements from list only\n",
        "def crop_list(lst,thres=29):\n",
        "  if len(lst)<thres:\n",
        "    return lst\n",
        "  else:\n",
        "    return lst[:thres]\n",
        "\n",
        "#converts urls to dataframes to excel sheets\n",
        "#get_max= get the maximum number of tables from each url\n",
        "#min_rows= the minimum number of rows in each table to save it to the excel sheet\n",
        "#crop_name_thres= some excel sheets can get quite huge sheet names which blows up the code\n",
        "#so crop the sheet name for the better purpose\n",
        "\n",
        "def urls_to_excel(urls,excel_path=None,get_max=10,min_rows=0,crop_name_thres=29):\n",
        "  excel_path=os.path.join(os.getcwd(),\"Excel_Multiple_Sheets_Output.xlsx\") if excel_path==None else excel_path\n",
        "  writer = pd.ExcelWriter(excel_path, engine='xlsxwriter')\n",
        "  i=0\n",
        "  for url in urls:\n",
        "    parsed=urlsplit(url)\n",
        "    sheet_name=parsed.path.split('/')[-1]\n",
        "    mod_sheet_name=crop_name(modify_name(sheet_name),thres=crop_name_thres)\n",
        "\n",
        "    dfs_list=get_dataframes(url)\n",
        "    filtered_dfs_list=filter_dfs(dfs_list,min_rows=min_rows)\n",
        "    filtered_dfs_list=crop_list(filtered_dfs_list,thres=get_max)\n",
        "    for each_df in filtered_dfs_list:\n",
        "      print(\"Parsing Excel Sheet \",\" : \",str(i)+mod_sheet_name)\n",
        "      i+=1\n",
        "      each_df.to_excel(writer, sheet_name=str(i)+mod_sheet_name, index=True)\n",
        "  writer.save()\n",
        "urls_to_excel(urls,get_max=100,min_rows=10)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XlsxWriter is not installed!!\n",
            "Collecting XlsxWriter\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/ce/74fd8d638a5b82ea0c6f08a5978f741c2655a38c3d6e82f73a0f084377e6/XlsxWriter-1.4.3-py2.py3-none-any.whl (149kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 4.3MB/s \n",
            "\u001b[?25hInstalling collected packages: XlsxWriter\n",
            "Successfully installed XlsxWriter-1.4.3\n",
            "3 Urls Found\n",
            "Parsing Excel Sheet   :  0ImpactFactorListJournals\n",
            "Parsing Excel Sheet   :  1IndexedJournalsList\n",
            "Parsing Excel Sheet   :  2\n",
            "Parsing Excel Sheet   :  3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bCJW9rl-PQ2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}